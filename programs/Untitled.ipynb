{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1288d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import ipywidgets as widgets\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # caused by some haystack duplication of processes, currently only a workaround\n",
    "\n",
    "sys.path.append('..') # for cheaha '..' is all that is needed here\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n",
    "\n",
    "from nlp.model import create_reader\n",
    "\n",
    "from haystack.nodes import FARMReader\n",
    "from haystack.nodes import TfidfRetriever\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.utils import clean_wiki_text, convert_files_to_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89da3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs\n"
     ]
    }
   ],
   "source": [
    "print(f'{os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc531563",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'zo_squad'\n",
    "\n",
    "model_dir = f'../readers/{data_name}'\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9d04bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -   * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/zo_squad.json\n",
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/.ipynb_checkpoints\n",
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/__init__.py\n",
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/__pycache__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.language_model -  Auto-detected model language: english\n",
      "INFO - haystack.modeling.model.language_model -  Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING TRAIN DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  ==================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Loading train set from: /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/zo_squad.json \n",
      "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00,  1.17 Dicts/s]\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING DEV DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  No dev set is being loaded\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING TEST DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  No test set is being loaded\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  DATASETS SUMMARY\n",
      "INFO - haystack.modeling.data_handler.data_silo -  ================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in train: 3703\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in dev  : 0\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in test : 0\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Total examples   : 3703\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  Longest sequence length observed after clipping:     256\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Average sequence length after clipping: 254.55576559546313\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Proportion clipped:      0.9497704563867134\n",
      "INFO - haystack.modeling.data_handler.data_silo -  [Haystack Tip] 95.0% of your samples got cut down to 256 tokens. Consider increasing max_seq_len (the maximum value allowed with the current model is max_seq_len=512, if this is not enough consider splitting the document in smaller units or changing the model). This will lead to higher memory consumption but is likely to improve your model performance\n",
      "INFO - haystack.modeling.model.optimization -  Loading optimizer 'AdamW': {'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}\n",
      "INFO - haystack.modeling.model.optimization -  Using scheduler 'get_linear_schedule_with_warmup'\n",
      "INFO - haystack.modeling.model.optimization -  Loading schedule 'get_linear_schedule_with_warmup': '{'num_training_steps': 371, 'num_warmup_steps': 74}'\n",
      "Train epoch 0/0 (Cur. train loss: 0.0005): 100%|██████████| 371/371 [01:46<00:00,  3.48it/s]\n",
      "INFO - haystack.nodes.reader.farm -  Saving reader model to my_model\n",
      "INFO - haystack.nodes.reader.farm -  Saving reader model to ../readers/zo_squad\n"
     ]
    }
   ],
   "source": [
    "reader = create_reader(model_dir, data_name, gpu=True, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "doc_dir = f\"{os.getcwd()}/data/text\"\n",
    "\n",
    "docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = TfidfRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c935b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FARMReader(model_name_or_path=model_dir, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3388fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa96e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-NLP-SPARQL]",
   "language": "python",
   "name": "conda-env-.conda-NLP-SPARQL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
