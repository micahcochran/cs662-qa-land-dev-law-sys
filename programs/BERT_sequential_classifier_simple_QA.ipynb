{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47fb97b5",
   "metadata": {},
   "source": [
    "# BERT sequential classifier as simple QA system\n",
    "\n",
    "This notebook is the code necessary to finetune a BERT sequence classifier as a QA system on our provided training and testing data.\n",
    "\n",
    "The data is comprised of zoning ordinance questions and their respective answers.\n",
    "\n",
    "This system was not designed to be a full fledged QA system but is created as a contrast to the more fully featured systems tested in other notebooks and implementations.\n",
    "\n",
    "To run this notebook simply run each cell in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf74530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "file_path = f'{os.getcwd()}/data'\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ff0a4",
   "metadata": {},
   "source": [
    "Printing the filepath to confirm that relative filepaths do not break on non local machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f660a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data\n"
     ]
    }
   ],
   "source": [
    "print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec0eaa",
   "metadata": {},
   "source": [
    "### Simple Additional Preprocessing:\n",
    "\n",
    "Examining the training set as a data frame to verify it's contents and running simple replace functions to clean up the questions and answers of any extraneous characters. The data has already been preprocessed once before by either the corpus builder or the template generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc4165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sparql</th>\n",
       "      <th>template_name</th>\n",
       "      <th>variables</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...</td>\n",
       "      <td>template_use_1var_m_answer</td>\n",
       "      <td>{'use': 'group care facilities'}</td>\n",
       "      <td>['C2', 'C3', 'C4']</td>\n",
       "      <td>Which zoning districts allow group care facili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...</td>\n",
       "      <td>template_use_1var_m_answer</td>\n",
       "      <td>{'use': 'group care facilities'}</td>\n",
       "      <td>['C2', 'C3', 'C4']</td>\n",
       "      <td>Which zoning districts permit group care facil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...</td>\n",
       "      <td>template_use_1var_m_answer</td>\n",
       "      <td>{'use': 'group care facilities'}</td>\n",
       "      <td>['C2', 'C3', 'C4']</td>\n",
       "      <td>I would like to build group care facilities. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...</td>\n",
       "      <td>template_use_1var_m_answer</td>\n",
       "      <td>{'use': 'dry cleaning plants'}</td>\n",
       "      <td>['FI1', 'FI2', 'FI3']</td>\n",
       "      <td>Which zoning districts allow dry cleaning plants?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...</td>\n",
       "      <td>template_use_1var_m_answer</td>\n",
       "      <td>{'use': 'dry cleaning plants'}</td>\n",
       "      <td>['FI1', 'FI2', 'FI3']</td>\n",
       "      <td>Which zoning districts permit dry cleaning pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sparql  \\\n",
       "0  \\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...   \n",
       "1  \\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...   \n",
       "2  \\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...   \n",
       "3  \\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...   \n",
       "4  \\nSELECT ?zoning_label\\n\\nWHERE {\\n        ?zo...   \n",
       "\n",
       "                template_name                         variables  \\\n",
       "0  template_use_1var_m_answer  {'use': 'group care facilities'}   \n",
       "1  template_use_1var_m_answer  {'use': 'group care facilities'}   \n",
       "2  template_use_1var_m_answer  {'use': 'group care facilities'}   \n",
       "3  template_use_1var_m_answer    {'use': 'dry cleaning plants'}   \n",
       "4  template_use_1var_m_answer    {'use': 'dry cleaning plants'}   \n",
       "\n",
       "                  answer                                           question  \n",
       "0     ['C2', 'C3', 'C4']  Which zoning districts allow group care facili...  \n",
       "1     ['C2', 'C3', 'C4']  Which zoning districts permit group care facil...  \n",
       "2     ['C2', 'C3', 'C4']  I would like to build group care facilities. W...  \n",
       "3  ['FI1', 'FI2', 'FI3']  Which zoning districts allow dry cleaning plants?  \n",
       "4  ['FI1', 'FI2', 'FI3']  Which zoning districts permit dry cleaning pla...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_df = pd.read_csv(f'{file_path}/csv/questions_answers.csv', low_memory=False)\n",
    "\n",
    "hf_dataset_df['question'] = hf_dataset_df['question'].str.replace('  ', ' ')\n",
    "hf_dataset_df['question'] = hf_dataset_df['question'].str.replace(',', '')\n",
    "\n",
    "hf_dataset_df.loc[hf_dataset_df['answer'] == 'True', 'answer'] = 'Yes'\n",
    "hf_dataset_df.loc[hf_dataset_df['answer'] == 'False', 'answer'] = 'No'\n",
    "\n",
    "hf_dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb0d96",
   "metadata": {},
   "source": [
    "### Creating classes dictionary:\n",
    "\n",
    "The sequence classifier is a multiclass classifier and requires numerical class representation. This dictionary will also be used to convert the predicted answers and ground truth labels back to their natural language format for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db523b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No': 1, 'Yes': 2, \"['0 [ft_i]']\": 3, \"['1 [du/acr_u]']\": 4, \"['10 [ft_i]']\": 5, \"['100 [ft_i]']\": 6, \"['10000 [sft_i]']\": 7, \"['12 [du/acr_u]']\": 8, \"['12 [u/acr_u]']\": 9, \"['125 [ft_i]']\": 10, \"['15 [ft_i]']\": 11, \"['150 [ft_i]']\": 12, \"['2 [du/acr_u]']\": 13, \"['20 [ft_i]']\": 14, \"['20000 [sft_i]']\": 15, \"['25 [ft_i]']\": 16, \"['30 [ft_i]']\": 17, \"['35 [ft_i]']\": 18, \"['35000 [sft_i]']\": 19, \"['4 [du/acr_u]']\": 20, \"['40 [ft_i]']\": 21, \"['5 [ft_i]']\": 22, \"['50 [ft_i]']\": 23, \"['6 [du/acr_u]']\": 24, \"['60 [ft_i]']\": 25, \"['6000 [sft_i]']\": 26, \"['70 [ft_i]']\": 27, \"['75 [ft_i]']\": 28, \"['8 [du/acr_u]']\": 29, \"['80 [ft_i]']\": 30, \"['90 [ft_i]']\": 31, \"['A1']\": 32, \"['A2']\": 33, \"['C1', 'C2', 'C3', 'C4', 'FI1', 'FI2', 'FI3']\": 34, \"['C1', 'C2', 'C3', 'C4']\": 35, \"['C2', 'C3', 'C4']\": 36, \"['C3', 'C4']\": 37, \"['C4']\": 38, \"['FI1', 'FI2', 'FI3']\": 39, \"['FI2', 'FI3']\": 40, \"['FI3']\": 41, \"['R1', 'R2', 'R3', 'C1', 'C2', 'C3', 'C4', 'FI1', 'FI2', 'FI3']\": 42, \"['R1', 'R2', 'R3', 'C1', 'C2', 'C3', 'C4']\": 43, \"['R1', 'R2', 'R3']\": 44, \"['R2', 'R3']\": 45, \"['R3']\": 46, '[]': 47}\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_df = hf_dataset_df.filter(['answer', 'question'], axis=1)\n",
    "\n",
    "uni = np.unique(hf_dataset_df['answer'], return_counts=True)\n",
    "\n",
    "d = dict(enumerate(uni[0].flatten(), 1))\n",
    "inv_map = {v: k for k, v in d.items()}\n",
    "print(inv_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca858ae8",
   "metadata": {},
   "source": [
    "Renaming columns for the finetuning process of the BERT tranformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54af905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>Which zoning districts allow group care facili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>Which zoning districts permit group care facil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>I would like to build group care facilities. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Which zoning districts allow dry cleaning plants?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Which zoning districts permit dry cleaning pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0     36  Which zoning districts allow group care facili...\n",
       "1     36  Which zoning districts permit group care facil...\n",
       "2     36  I would like to build group care facilities. W...\n",
       "3     39  Which zoning districts allow dry cleaning plants?\n",
       "4     39  Which zoning districts permit dry cleaning pla..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_df = hf_dataset_df.replace({'answer': inv_map})\n",
    "\n",
    "hf_dataset_df.rename(columns={'answer': 'label', 'question': 'text'}, inplace=True)\n",
    "\n",
    "hf_dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696dd8a",
   "metadata": {},
   "source": [
    "Test/train split and conversion to required json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9005389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(hf_dataset_df, test_size=0.1, random_state=246341428)\n",
    "\n",
    "train.to_json(f'{file_path}/json/QAZoningTrain.json', orient='records', lines=True)\n",
    "test.to_json(f'{file_path}/json/QAZoningTest.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89843e",
   "metadata": {},
   "source": [
    "### Tokenization and creation of Hugging Face Dataset class object\n",
    "\n",
    "The BERT model and tokenizer from Hugging Face require that the data be converted to a dataset object, hence the need for the train/test split to exist as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb294be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ffb13f45da879356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': '/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/json/QAZoningTrain.json', 'test': '/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/json/QAZoningTest.json'}\n",
      "Downloading and preparing dataset json/default to /home/jesusaur/.cache/huggingface/datasets/json/default-ffb13f45da879356/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f8cf8fb6d4b2a8be788d6c89f89e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362ba77504f14e9cab7759d3a04d9d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #0:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5685ae2c904cea91b3c16c60ef1622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #1:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/jesusaur/.cache/huggingface/datasets/json/default-ffb13f45da879356/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f779921862614b999ea7514e5f6ab8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 955\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 107\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", lower=True)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "data_files = {\"train\": f'{file_path}/json/QAZoningTrain.json', \"test\": f'{file_path}/json/QAZoningTest.json'} # * this is how to load multiple files, need to sklearn train_test_split into two sets first\n",
    "print(data_files)\n",
    "QA_dataset = load_dataset('json', data_files=data_files)\n",
    "print(QA_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e50470",
   "metadata": {},
   "source": [
    "### Training and Evaluation Parameters\n",
    "\n",
    "Initialization of the pretrained model and tokenization of dataset.\n",
    "\n",
    "These are the parameters used for training and evaluation in the process of finetuning the model.\n",
    "\n",
    "Metrics selected were Accuracy and F1 from the Hugging Face Evaluate library.\n",
    "\n",
    "The model is evaluated and saved at each epoch.\n",
    "\n",
    "There is opportunity for additional hyperparameter tuning at this stage but results were adequate using these initial parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d624fe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c53b84906ac4170bebdeac3e3fec163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d29da342c74c75a861106791facfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = QA_dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=48)\n",
    "\n",
    "metric1 = evaluate.load('f1')\n",
    "metric2 = evaluate.load('accuracy')\n",
    "\n",
    "training_args = TrainingArguments(output_dir = \"test_trainer\",\n",
    "                                  evaluation_strategy = \"epoch\",\n",
    "                                  save_strategy = \"epoch\",\n",
    "                                  do_train=True,\n",
    "                                  do_eval=True,\n",
    "                                  learning_rate=1e-5,\n",
    "                                  logging_steps=50,\n",
    "                                  eval_steps=50,\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8,\n",
    "                                  num_train_epochs=25,\n",
    "                                  weight_decay=0.001,)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1 = metric1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    accuracy = metric2.compute(predictions=predictions, references=labels)\n",
    "    return {\"accuracy\": accuracy['accuracy'], \"f1\": f1['f1']}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab8cf8",
   "metadata": {},
   "source": [
    "Fine tunining the pretrained model begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ebfceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/jesusaur/.conda/envs/NLP-SPARQL/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 955\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3000\n",
      "Trainer is attempting to log a value of \"{0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3', 4: 'LABEL_4', 5: 'LABEL_5', 6: 'LABEL_6', 7: 'LABEL_7', 8: 'LABEL_8', 9: 'LABEL_9', 10: 'LABEL_10', 11: 'LABEL_11', 12: 'LABEL_12', 13: 'LABEL_13', 14: 'LABEL_14', 15: 'LABEL_15', 16: 'LABEL_16', 17: 'LABEL_17', 18: 'LABEL_18', 19: 'LABEL_19', 20: 'LABEL_20', 21: 'LABEL_21', 22: 'LABEL_22', 23: 'LABEL_23', 24: 'LABEL_24', 25: 'LABEL_25', 26: 'LABEL_26', 27: 'LABEL_27', 28: 'LABEL_28', 29: 'LABEL_29', 30: 'LABEL_30', 31: 'LABEL_31', 32: 'LABEL_32', 33: 'LABEL_33', 34: 'LABEL_34', 35: 'LABEL_35', 36: 'LABEL_36', 37: 'LABEL_37', 38: 'LABEL_38', 39: 'LABEL_39', 40: 'LABEL_40', 41: 'LABEL_41', 42: 'LABEL_42', 43: 'LABEL_43', 44: 'LABEL_44', 45: 'LABEL_45', 46: 'LABEL_46', 47: 'LABEL_47'}\" for key \"id2label\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n",
      "Trainer is attempting to log a value of \"{'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3, 'LABEL_4': 4, 'LABEL_5': 5, 'LABEL_6': 6, 'LABEL_7': 7, 'LABEL_8': 8, 'LABEL_9': 9, 'LABEL_10': 10, 'LABEL_11': 11, 'LABEL_12': 12, 'LABEL_13': 13, 'LABEL_14': 14, 'LABEL_15': 15, 'LABEL_16': 16, 'LABEL_17': 17, 'LABEL_18': 18, 'LABEL_19': 19, 'LABEL_20': 20, 'LABEL_21': 21, 'LABEL_22': 22, 'LABEL_23': 23, 'LABEL_24': 24, 'LABEL_25': 25, 'LABEL_26': 26, 'LABEL_27': 27, 'LABEL_28': 28, 'LABEL_29': 29, 'LABEL_30': 30, 'LABEL_31': 31, 'LABEL_32': 32, 'LABEL_33': 33, 'LABEL_34': 34, 'LABEL_35': 35, 'LABEL_36': 36, 'LABEL_37': 37, 'LABEL_38': 38, 'LABEL_39': 39, 'LABEL_40': 40, 'LABEL_41': 41, 'LABEL_42': 42, 'LABEL_43': 43, 'LABEL_44': 44, 'LABEL_45': 45, 'LABEL_46': 46, 'LABEL_47': 47}\" for key \"label2id\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 23:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.200900</td>\n",
       "      <td>1.643808</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.082477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.426900</td>\n",
       "      <td>1.308724</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.146278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.169600</td>\n",
       "      <td>1.182571</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.164993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.022900</td>\n",
       "      <td>1.114107</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.145995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.039837</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.213068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.880500</td>\n",
       "      <td>0.968154</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.277480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>0.903104</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.328102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.812674</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.383548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.668600</td>\n",
       "      <td>0.755517</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.441397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.704456</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.475810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.655158</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.472436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.613506</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.520147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.572001</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.488536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.510262</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.537919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.493694</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.473322</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.462230</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.451963</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.438206</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.537919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.430963</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.424831</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.421842</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.419677</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.418586</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-120\n",
      "Configuration saved in test_trainer/checkpoint-120/config.json\n",
      "Model weights saved in test_trainer/checkpoint-120/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-240\n",
      "Configuration saved in test_trainer/checkpoint-240/config.json\n",
      "Model weights saved in test_trainer/checkpoint-240/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-360\n",
      "Configuration saved in test_trainer/checkpoint-360/config.json\n",
      "Model weights saved in test_trainer/checkpoint-360/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-480\n",
      "Configuration saved in test_trainer/checkpoint-480/config.json\n",
      "Model weights saved in test_trainer/checkpoint-480/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-600\n",
      "Configuration saved in test_trainer/checkpoint-600/config.json\n",
      "Model weights saved in test_trainer/checkpoint-600/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-720\n",
      "Configuration saved in test_trainer/checkpoint-720/config.json\n",
      "Model weights saved in test_trainer/checkpoint-720/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-840\n",
      "Configuration saved in test_trainer/checkpoint-840/config.json\n",
      "Model weights saved in test_trainer/checkpoint-840/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-960\n",
      "Configuration saved in test_trainer/checkpoint-960/config.json\n",
      "Model weights saved in test_trainer/checkpoint-960/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1080\n",
      "Configuration saved in test_trainer/checkpoint-1080/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1080/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1200\n",
      "Configuration saved in test_trainer/checkpoint-1200/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1200/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1320\n",
      "Configuration saved in test_trainer/checkpoint-1320/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1320/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1440\n",
      "Configuration saved in test_trainer/checkpoint-1440/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1440/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1560\n",
      "Configuration saved in test_trainer/checkpoint-1560/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1560/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1680\n",
      "Configuration saved in test_trainer/checkpoint-1680/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1680/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1800\n",
      "Configuration saved in test_trainer/checkpoint-1800/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1800/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1920\n",
      "Configuration saved in test_trainer/checkpoint-1920/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1920/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2040\n",
      "Configuration saved in test_trainer/checkpoint-2040/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2040/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2160\n",
      "Configuration saved in test_trainer/checkpoint-2160/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2160/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2280\n",
      "Configuration saved in test_trainer/checkpoint-2280/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2280/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2400\n",
      "Configuration saved in test_trainer/checkpoint-2400/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2400/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2520\n",
      "Configuration saved in test_trainer/checkpoint-2520/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2520/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2640\n",
      "Configuration saved in test_trainer/checkpoint-2640/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2640/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2760\n",
      "Configuration saved in test_trainer/checkpoint-2760/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2760/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2880\n",
      "Configuration saved in test_trainer/checkpoint-2880/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2880/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-3000\n",
      "Configuration saved in test_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.6526463314692179, metrics={'train_runtime': 1432.0539, 'train_samples_per_second': 16.672, 'train_steps_per_second': 2.095, 'total_flos': 6284370917376000.0, 'train_loss': 0.6526463314692179, 'epoch': 25.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4cf38",
   "metadata": {},
   "source": [
    "Evaluation occurs during training but addition of this call to evaluate() allows us to print the best model's final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94dc6dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4185863137245178,\n",
       " 'eval_accuracy': 0.897196261682243,\n",
       " 'eval_f1': 0.5132275132275131,\n",
       " 'eval_runtime': 2.0396,\n",
       " 'eval_samples_per_second': 52.461,\n",
       " 'eval_steps_per_second': 6.864,\n",
       " 'epoch': 25.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f5d65",
   "metadata": {},
   "source": [
    "Simple function to map classes back to their natural language counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e3751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(d, value):\n",
    "   return [k for k, v in d.items() if v == value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8afdb",
   "metadata": {},
   "source": [
    "### Checking some results:\n",
    "\n",
    "Below is a sanity check to see what kind of results are returned after the model is trained.\n",
    "\n",
    "We have provided two correct results but feel free to explore using the same format to find an incorrect example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b51f4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('I would like to build physical fitness centers. Which zoning districts permits this use?',\n",
       " [\"['C2', 'C3', 'C4']\"],\n",
       " [\"['C2', 'C3', 'C4']\"])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = trainer.predict(tokenized_data[\"test\"])\n",
    "results = (tokenized_data[\"test\"][19]['text'], get_key(inv_map, np.argmax(prediction[0][19], axis=-1)), \n",
    "          get_key(inv_map, prediction[1][19]))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "596d8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 107\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Are monument works allowed in a FI2 zoning district?', ['Yes'], ['Yes'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = trainer.predict(tokenized_data[\"test\"])\n",
    "results = (tokenized_data[\"test\"][7]['text'], get_key(inv_map, np.argmax(prediction[0][7], axis=-1)), \n",
    "          get_key(inv_map, prediction[1][7]))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600439f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:NLP-SPARQL]",
   "language": "python",
   "name": "conda-env-NLP-SPARQL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
