{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f8ea19",
   "metadata": {},
   "source": [
    "# ROBERTA SQuAD QA System Using Zoning Corpus with Fine Tuning\n",
    "\n",
    "This notebook is the code necessary to experiment with a pretrained ROBERTA QA system trained on SQuAD data with the benefit of fine tuning on our annotated training data.\n",
    "\n",
    "Results were expected to be mediocre but testing indicated that the system shows promise.\n",
    "\n",
    "It should be noted that annotated data was made from a custom zoning corpus preprocessed by our custom corpus builder and that the amount of annotated data was limited to a size that did not allow for splitting into train and test sets. As we continue annotation of the corpus this problem will resolve itself and despite this shortcoming the system did often provide the expected answers.\n",
    "\n",
    "To run this notebook simply run each cell in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbd3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import ipywidgets as widgets\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # caused by some haystack duplication of processes, currently only a workaround\n",
    "\n",
    "sys.path.append('..') # for cheaha '..' is all that is needed here\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n",
    "\n",
    "from nlp.model import create_reader\n",
    "\n",
    "from haystack.nodes import FARMReader\n",
    "from haystack.nodes import TfidfRetriever\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.utils import clean_wiki_text, convert_files_to_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e4cce",
   "metadata": {},
   "source": [
    "Printing the filepath to confirm that relative filepaths do not break on non local machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220cf711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs\n"
     ]
    }
   ],
   "source": [
    "print(f'{os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5daa00",
   "metadata": {},
   "source": [
    "setting the path to the in library data store where the annotated SQuAD 2.0 dataset on zoning ordinances resides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed383552",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'zo_squad'\n",
    "\n",
    "model_dir = f'../readers/{data_name}'\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ea1a2",
   "metadata": {},
   "source": [
    "### Custom Reader Class:\n",
    "\n",
    "For fine tuning it was necessary to create a custom reader class that automates much of the processes needed to fine tune the pretrained Haystack reader.\n",
    "\n",
    "Options for training not seen here are sequence length and increasing the dev split to provide an evaluation split in future implementations. However, on the limited amount of data available for training the defaults and using only 3 epochs proved sufficient for a proof of concept.\n",
    "\n",
    "If you would like to view the custom readers, tokenizers, and corpus builders please look in the /nlp/ folder of this library.\n",
    "\n",
    "Addtionally it was discovered that for training to occur on a single GPU the corpus data had to be split into 300 or less sentence chunks. \n",
    "\n",
    "**Do not run this section if you have previously trained the reader, for expediency we have saved the model at this step and it can be loaded into the reader object in the following cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc280439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/zo_squad.json\n",
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/.ipynb_checkpoints\n",
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/__init__.py\n",
      "/data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/__pycache__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.language_model -   * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n",
      "INFO - haystack.modeling.model.language_model -  Auto-detected model language: english\n",
      "INFO - haystack.modeling.model.language_model -  Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING TRAIN DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  ==================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Loading train set from: /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/../nlp/model/data/question_answering/zo_squad/zo_squad.json \n",
      "Preprocessing dataset: 100%|██████████| 1/1 [00:01<00:00,  1.23s/ Dicts]\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING DEV DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  No dev set is being loaded\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING TEST DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  No test set is being loaded\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  DATASETS SUMMARY\n",
      "INFO - haystack.modeling.data_handler.data_silo -  ================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in train: 3703\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in dev  : 0\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in test : 0\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Total examples   : 3703\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  Longest sequence length observed after clipping:     256\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Average sequence length after clipping: 254.55576559546313\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Proportion clipped:      0.9497704563867134\n",
      "INFO - haystack.modeling.data_handler.data_silo -  [Haystack Tip] 95.0% of your samples got cut down to 256 tokens. Consider increasing max_seq_len (the maximum value allowed with the current model is max_seq_len=512, if this is not enough consider splitting the document in smaller units or changing the model). This will lead to higher memory consumption but is likely to improve your model performance\n",
      "INFO - haystack.modeling.model.optimization -  Loading optimizer 'AdamW': {'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}\n",
      "INFO - haystack.modeling.model.optimization -  Using scheduler 'get_linear_schedule_with_warmup'\n",
      "INFO - haystack.modeling.model.optimization -  Loading schedule 'get_linear_schedule_with_warmup': '{'num_training_steps': 1113, 'num_warmup_steps': 222}'\n",
      "Train epoch 0/2 (Cur. train loss: 0.0008): 100%|██████████| 371/371 [01:47<00:00,  3.44it/s]\n",
      "Train epoch 1/2 (Cur. train loss: 0.0892): 100%|██████████| 371/371 [01:46<00:00,  3.47it/s]\n",
      "Train epoch 2/2 (Cur. train loss: 0.4041): 100%|██████████| 371/371 [01:46<00:00,  3.48it/s]\n",
      "INFO - haystack.nodes.reader.farm -  Saving reader model to my_model\n",
      "INFO - haystack.nodes.reader.farm -  Saving reader model to ../readers/zo_squad\n"
     ]
    }
   ],
   "source": [
    "reader = create_reader(model_dir, data_name, dev_split=0.0, gpu=True, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3677f0b",
   "metadata": {},
   "source": [
    "## Creation of in memory document store:\n",
    "\n",
    "Using Deepset's Haystack library we are able to create an in memory store of the documents from which answers should be retrieved. Haystack provides web based stores but local was necessary at this stage of development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa140e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_2.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_3.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_14.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_11.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_12.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_18.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_13.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_5.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_7.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_1.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_4.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_15.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_8.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_17.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_10.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_6.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_9.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_16.txt\n",
      "INFO - haystack.utils.preprocessing -  Converting /data/user/home/jesusaur/cs662-qa-land-dev-law-sys/programs/data/text/text_0.txt\n"
     ]
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "doc_dir = f\"{os.getcwd()}/data/text\"\n",
    "\n",
    "docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f351a4",
   "metadata": {},
   "source": [
    "creation of the document retriever object which tries to identify the correct documents to be used by the \"reader\" object in the QA system's answering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebbab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.sparse -  Found 78 candidate paragraphs from 19 docs in DB\n"
     ]
    }
   ],
   "source": [
    "retriever = TfidfRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e61f6",
   "metadata": {},
   "source": [
    "### Load the newly fine tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffda4581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -   * LOADING MODEL: '../readers/zo_squad' (Roberta)\n",
      "INFO - haystack.modeling.model.language_model -  Loaded '../readers/zo_squad' (Roberta model) from local file system.\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": true, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from ../readers/zo_squad/prediction_head_0.bin\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=model_dir, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768bbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64828c1",
   "metadata": {},
   "source": [
    "we have added a text entry field here for testing the system without fine tuning. please enter a zoning related question into the text field after running this cell followed by running the cell after to see the QA system output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0797337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d844342f73842bf863b4c788f2089aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Question:', placeholder='Enter your question.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txtsl = widgets.Text( # 'Which zoning districts allow group care facilities?'\n",
    " placeholder='Enter your question.',\n",
    " description='Question:'\n",
    " )\n",
    "display(txtsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc5cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which zones permit indoor theaters?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 7/7 [00:02<00:00,  2.95 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "print(f'Question: {txtsl.value}')\n",
    "prediction = pipe.run(\n",
    "    query=txtsl.value, params={\"Retriever\": {\"top_k\": 20}, \"Reader\": {\"top_k\": 2}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9192cf",
   "metadata": {},
   "source": [
    "The following cells are the output of the model based on the question entered into the text field above. Please observe that confidence scores are provided with each answer and that we have decided to provide the top two answers since it was sometimes the case that the second answer was correct in the even that the first was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c45723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Answer {'answer': 'C3, which includes amusement centers including bowling alleys, golf driving ranges, miniature golf courses, ice skating rinks, pool and billiard halls; and C4, which includes major automotive repair, manufacturing and commercial centers', 'type': 'extractive', 'score': 0.8879691958427429, 'context': 'C3, which includes amusement centers including bowling alleys, golf driving ranges, miniature golf courses, ice skating rinks, pool and billiard halls; and C4, which includes major automotive repair, manufacturing and commercial centers', 'offsets_in_document': [{'start': 4763, 'end': 4999}], 'offsets_in_context': [{'start': 0, 'end': 236}], 'document_id': '51d9574bffbcd3dd446782323416b218', 'meta': {'name': 'text_1.txt'}}>,\n",
      " <Answer {'answer': 'RESIDENTIAL ZONES', 'type': 'extractive', 'score': 0.8432620763778687, 'context': 'NTERNATIONAL ZONING CODE”  CHAPTER 5 RESIDENTIAL ZONES SECTION 501 RESIDENTIAL ZONES DEFINED 501.1 Residential zone. Allowable residential (R) zone us', 'offsets_in_document': [{'start': 6322, 'end': 6339}], 'offsets_in_context': [{'start': 67, 'end': 84}], 'document_id': '7a98d21fe50cfbc418dc8fa5e9a68798', 'meta': {'name': 'text_7.txt'}}>]\n"
     ]
    }
   ],
   "source": [
    "pprint(prediction['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35260f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Which zones allow quarries?\n",
      "Answers:\n",
      "[   <Answer {'answer': 'Division 3. Any use permitted in the FI, Division 2 zone and auto-dismantling yards, alcohol manufacturing, cotton gins, paper manufacturing, quarries, salt works, petroleum refining, and other similar uses', 'type': 'extractive', 'score': 0.9963598847389221, 'context': 'Division 3. Any use permitted in the FI, Division 2 zone and auto-dismantling yards, alcohol manufacturing, cotton gins, paper manufacturing, quarries, salt works, petroleum refining, and other similar uses', 'offsets_in_document': [{'start': 6278, 'end': 6484}], 'offsets_in_context': [{'start': 0, 'end': 206}], 'document_id': '43f2a4f50fd4bc8b4b8b8aae557ee365', 'meta': {'name': 'text_8.txt'}}>,\n",
      "    <Answer {'answer': 'C1, which includes minor automotive repair and automotive fuel dispensing facilities; C2, which includes light commercial and group care facilities; C3, which includes amusement centers including bowling alleys, golf driving ranges, miniature golf courses, ice skating rinks, pool and billiard halls; and C4, which includes major automotive repair, manufacturing and commercial centers', 'type': 'extractive', 'score': 0.8263331055641174, 'context': ' C1, which includes minor automotive repair and automotive fuel dispensing facilities; C2, which includes light commercial and group care facilities; C3, which includes amusement centers including bowling alleys, golf driving ranges, miniature golf courses, ice skating rinks, pool and billiard halls; and C4, which includes major automotive repair, manufacturing and commercial centers', 'offsets_in_document': [{'start': 4614, 'end': 4999}], 'offsets_in_context': [{'start': 1, 'end': 386}], 'document_id': '51d9574bffbcd3dd446782323416b218', 'meta': {'name': 'text_1.txt'}}>]\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import print_answers\n",
    "\n",
    "print_answers(prediction, details=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf5717",
   "metadata": {},
   "source": [
    "### Promising results:\n",
    "\n",
    "Despite the small amount of training data the system appears to be able to answer zoning questions correctly even when worded outside of the explicit training questions. Though squad is limited in its ability to answer yes or no questions, it will provide context related to the keywords of the question sometimes to the equivalent effect of a affirmative response. The system has exhibited on occasion to answer questions on the provided corpus that were not at all similar to the training data.\n",
    "\n",
    "Because of these facts we believe that there is promise to this method and are considering how we might ensemble it with the KG versions of our QA system, and that thes system can only improve using larger pretrained SQuAD models and a more complete annotation set for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdda945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:NLP-SPARQL]",
   "language": "python",
   "name": "conda-env-NLP-SPARQL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
